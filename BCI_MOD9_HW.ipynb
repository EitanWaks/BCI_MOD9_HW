{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 585.783 Introduction to Brain Computer Interfaces\n",
    "## Mod 9 - Brain-Computer Interfacing – Introduction to Brain Computer Interfaces\n",
    "\n",
    "### Date Submitted: August, DAY, 2022\n",
    "\n",
    "### Eitan Waks\n",
    "\n",
    "Answer the following questions using the robintibor/high-gamma-dataset – specifically data/train/1.mat.  Make sure you provide a notebook or source code as an appendix to this assignment.  Again, make sure all plots have labeled axes and meaningful titles.\n",
    "\n",
    "Hint: You should be able to copy paste and re-use sections from the lecture notebooks provided in this module to complete this assignment with very little coding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Q1.  **Outperform the professor.**\n",
    "\n",
    "Your only responsibility for this homework is to build a neural classifier for the provided dataset that outperforms the one we presented in lecture.  You are free to just jump in and start modifying the lecture notebooks to derive a better result on the four-class classification problem.\n",
    "\n",
    "***Please continue to use leave-one-out cross-validation*** when reporting your classification results.  You will be graded on substantive changes to the analysis that result in substantive performance changes in classification. Simply changing the random seeds used in the classifier methods, you might randomly get a slightly better classification performance, but this would not constitute a meaningful change in the analysis\n",
    "\n",
    "When I ran the four-class problem with leave-one out classification, I achieved 50% accuracy.  I would consider performance >= 65% to be a substantive change in accuracy.  Remember that chance performance for a 4-class problem is 25%.\n",
    "\n",
    "Things you might try:\n",
    "- Feature Engineering\n",
    "    - New signal processing (maybe multi-taper spectrograms?)\n",
    "    - Sub-select new frequencies \n",
    "    (Hint: there might be some useful content between 70 and 80 Hz ;) )\n",
    "    - Sub-select channels, or possibly different time-periods w.r.t. trial onset.\n",
    "- New Classifier\n",
    "    - Try an SVM classifier, or a logistic regression.  Random forests?\n",
    "- Outlier Rejection\n",
    "    - There might be some bad trials mixed into the dataset, try manually cleaning the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess your performance in this homework, I would like to see the following content in a short report (1-2 pages).\n",
    "1.\tDescription of task and trial types (1, 2, 3, 4) and what the subject was actually doing during these trial types. (You can get this from reading the paper associated from the dataset, https://onlinelibrary.wiley.com/doi/full/10.1002/hbm.23730 or by examining the topographic spectrograms) [4 pts]\n",
    "2.\t2-3 paragraph description of your change to the analysis and what changes you made to get better performance [8 pts]\n",
    "3.\tConfusion plot showing your classifier’s performance across different conditions.  Provide a short description of what the confusion plot means, and which trial types are being confused with each-other. \n",
    "See https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html for more information on confusion plots. [4pts]\n",
    "4.\tModel Introspection: Please provide a plot or two and a 1 paragraph description of what frequencies, channels, post-trial timings are contributing to your model’s performance. [4pts] (NB: to get these 4 points, you should probably pick a model that lends itself well to introspection – deep learning may not be what you want to use for this homework, but if you think you can successfully introspect and explain the deep network, be my guest.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import mne\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "dataset_name = '1'\n",
    "dataset_filetype = 'edf'\n",
    "repository = 'BCI_MOD9_HW'\n",
    "app_dir = Path('/', 'app')\n",
    "data_dir = app_dir.joinpath('data')\n",
    "notebook_dir = app_dir.joinpath(repository)\n",
    "data_file = data_dir.joinpath(f'{dataset_name}.{dataset_filetype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Montage -- Channel names in this file adhere to 10-05\n",
    "montage = mne.channels.make_standard_montage('standard_1005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "chs_EOG = ['EOG EOGh', 'EOG EOGv']\n",
    "chs_EMG = ['EMG EMG_RH', 'EMG EMG_LH', 'EMG EMG_RF']\n",
    "raw = mne.io.read_raw_edf(data_file, eog=chs_EOG, misc=chs_EMG, stim_channel='auto', exclude=(), infer_types=False, preload=True, verbose=None)\n",
    "original_raw = raw.copy()\n",
    "# Get events from the database\n",
    "annotations = raw.annotations\n",
    "events_from_annot, event_dict = mne.events_from_annotations(raw)\n",
    "# epoch surrounding trial onset.\n",
    "fs = raw.info['sfreq']\n",
    "starttime = -3\n",
    "endtime = 3\n",
    "timebase_samp = np.arange(int(fs*starttime), int(fs*endtime))\n",
    "timebase_sec = timebase_samp/fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-reference to the common average using MNE\n",
    "raw_car = raw.copy().set_eeg_reference('average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample\n",
    "raw_resampled = raw_car.copy().resample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bandpass filter\n",
    "lowpass_freq = 1\n",
    "highpass_freq = 30\n",
    "raw_filtered = raw_car.copy().filter(l_freq=lowpass_freq, h_freq=highpass_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set list of all channels whose name contains the string “AF” and the corresponding indeces\n",
    "AF_ch = [ch for ch in raw.ch_names if 'AF' in ch]\n",
    "raw_filtered_AF = raw_filtered.copy().pick(AF_ch)  # selects only the EEG channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all channels whose name contains the string “AF”. \n",
    "# A 10 second stretch beginning at 200 seconds into the file\n",
    "starttime = 200\n",
    "duration = 10\n",
    "fig01 = raw_filtered_AF.plot(events=None, duration=duration, start=starttime, n_channels=len(AF_ch), \n",
    "    title=f'EEG of AF channels, common average referenced and bandpass filtered between 1 and 30 Hz, beginning at {starttime} seconds for a duration of {duration} seconds', \n",
    "    show_scrollbars=False, show_scalebars=True, time_format='float')\n",
    "fig01.show()\n",
    "fig01.savefig(f'AF_EEG_{starttime}_{duration}.png', dpi=100, format='png', metadata={'Title': f'AF_EEG_{starttime}_{duration}', 'Author': 'Eitan Waks', \n",
    "            'Description': f'EEG plot of {AF_ch} channels, preprocessed with common average reference and bandpass filtered between 1 and 30 Hz, starting at {starttime} seconds for a duration of {duration} seconds. The data is from the robintibor/high-gamma-dataset (data/train/1.edf)'},\n",
    "            bbox_inches=None, pad_inches=0.1, facecolor='auto', edgecolor='auto', backend=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set list of channels and corresponding indeces. Get channel data\n",
    "chs = ['EEG Cz', 'EEG C3', 'EEG C4', 'EEG Pz', 'EEG Oz']\n",
    "ch_idxs = [raw.ch_names.index(ch) for ch in chs]\n",
    "raw_filtered_chs = raw_filtered.copy().pick(chs)  # selects only the 'EEG Cz', 'EEG C3', 'EEG C4', 'EEG Pz', 'EEG Oz' channels\n",
    "raw_filtered_chs_data, raw_filtered_chs_t = raw_filtered_chs.copy()[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory of events according to event type\n",
    "idxs = list(range(0, len(events_from_annot), 1))\n",
    "events = event_dict.copy()\n",
    "events['feet'] = [events_from_annot[idx][0] for idx in idxs if events_from_annot[idx][2]==event_dict['feet']]\n",
    "events['left_hand'] = [events_from_annot[idx][0] for idx in idxs if events_from_annot[idx][2]==event_dict['left_hand']]\n",
    "events['rest'] = [events_from_annot[idx][0] for idx in idxs if events_from_annot[idx][2]==event_dict['rest']]\n",
    "events['right_hand'] = [events_from_annot[idx][0] for idx in idxs if events_from_annot[idx][2]==event_dict['right_hand']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of event epochs according to type\n",
    "events_epochs = event_dict.copy()\n",
    "events_epochs['feet'] = [events['feet'][idx] + timebase_samp for idx in list(range(0, len(events['feet']), 1))]\n",
    "events_epochs['left_hand'] = [events['left_hand'][idx] + timebase_samp for idx in list(range(0, len(events['left_hand']), 1))]\n",
    "events_epochs['rest'] = [events['rest'][idx] + timebase_samp for idx in list(range(0, len(events['rest']), 1))]\n",
    "events_epochs['right_hand'] = [events['right_hand'][idx] + timebase_samp for idx in list(range(0, len(events['right_hand']), 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of event values split by trial type and epoch\n",
    "events_epochs_values = event_dict.copy()\n",
    "events_epochs_values['feet'] = [raw_filtered_chs_data[:,events_epochs['feet'][idx]] for idx in list(range(0, len(events_epochs['feet']), 1))]\n",
    "events_epochs_values['left_hand'] = [raw_filtered_chs_data[:,events_epochs['left_hand'][idx]] for idx in list(range(0, len(events_epochs['left_hand']), 1))]\n",
    "events_epochs_values['rest'] = [raw_filtered_chs_data[:,events_epochs['rest'][idx]] for idx in list(range(0, len(events_epochs['rest']), 1))]\n",
    "events_epochs_values['right_hand'] = [raw_filtered_chs_data[:,events_epochs['right_hand'][idx]] for idx in list(range(0, len(events_epochs['right_hand']), 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch_idx, ch in enumerate(chs):\n",
    "    fig, axs = plt.subplots( nrows=2, ncols=2, dpi=100, figsize=(9.0,6.0), constrained_layout=True, sharex=True, sharey=True)\n",
    "    fig.suptitle(f'{ch} Trial Average ERP', fontsize=16)\n",
    "    fig.supxlabel('Time (sec) relative to trial onset')\n",
    "    fig.supylabel('Voltage (uV)')\n",
    "    for nn, ax in enumerate(axs.flat):\n",
    "        line_width = 2.0\n",
    "        ax.set_xlim(-1.0, 3.0)\n",
    "        ax.set_ylim([-19.0, 10.0])\n",
    "        ax.grid()\n",
    "        column = list(event_dict.copy().keys())[nn]\n",
    "        ax.set_title(column, fontsize='small', loc='center')\n",
    "        for event_type_idx, event_type in enumerate(event_dict):\n",
    "            erp = events_epochs_values[event_type][:][ch_idx][:].mean(axis=0)\n",
    "            erp = erp*1e6\n",
    "            \n",
    "            if nn == 0 and event_type == \"left_hand\":\n",
    "                ax.plot(timebase_sec, erp, lw=line_width)\n",
    "                break;\n",
    "            elif nn == 1 and event_type == \"right_hand\":\n",
    "                ax.plot(timebase_sec, erp, lw=line_width)\n",
    "                break;\n",
    "            elif nn == 2 and event_type == \"feet\":\n",
    "                ax.plot(timebase_sec, erp, lw=line_width)\n",
    "                break;\n",
    "            elif nn == 3 and event_type == \"rest\":\n",
    "                ax.plot(timebase_sec, erp, lw=line_width)\n",
    "                break;\n",
    "            else:\n",
    "                pass\n",
    "    plt.show()\n",
    "    plt.savefig(f'{ch}.png', dpi=100, format='png', metadata={'Title': f'{ch}', 'Author': 'Eitan Waks', \n",
    "            'Description': f'The trial average ERP for EEG channel {ch} for all trial types from the robintibor/high-gamma-dataset (data/train/1.edf)'},\n",
    "            bbox_inches=None, pad_inches=0.1, facecolor='auto', edgecolor='auto', backend=None\n",
    "       )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "bf346314c43a4e41a109f13c23ca3f44734b8d745e9df5014829b5c89ef1cafd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
